{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lokVHWdvaz-W"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/PUBLIC_HEALTH_MENTION.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oex6UyiHHpJS"
      },
      "source": [
        "# **Public Health Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-UAcTkUbjzm"
      },
      "source": [
        "# **Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GlpBHUvcWup"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_6oU-alKz3e"
      },
      "source": [
        "# **Install dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COP6jvxkKwz5"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lXpEF3cK5xW"
      },
      "source": [
        "# **Import dependencies into Python and start the Spark session**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "gY2iy25_K7y_",
        "outputId": "8c19b8e3-18fd-4b0a-fdf1-bc94bba25c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 4.1.0\n",
            "Spark NLP_JSL Version : 4.1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f1144c5ba50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e3f1fdd3413a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.util import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.pretrained import ResourceDownloader\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(secret = SECRET, params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sample Text**"
      ],
      "metadata": {
        "id": "hWqrjHjoirOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JHleRuSGJqd5"
      },
      "outputs": [],
      "source": [
        "text_list = [\n",
        "\"\"\"Got sumatriptan for this week long migraine  I thought these were over as a kid  but I guess not  Thought I could just baby it a couple days with water and pedialyte and excedrin  Nope    Why am I so stubborn about continuing to  DO THINGA when I m obviously not well\"\"\",\n",
        "\"\"\"That Thunder trade alert just now from  almost gave me a heart attack  Was bracing myself to see THUNDER SENDS RUSS TO Wow That was the briefest emotional roller coaster ever\"\"\",\n",
        "\"\"\"The sickle cell clinic of  still goes on  It is even more for the next 2 months  Ever heard of childhood stroke  One of the leading causes of childhood stroke is sickle cell  Amidst cancer and other\"\"\",\n",
        "\"\"\"In 2015 I suffered a stroke  This prevented me from playing Rugby League again  It was difficult physically and mentally to recover from  bit four years later  here I am  about to embark on this   Read my story and please donate if you can\"\"\",\n",
        "\"\"\"i respect the fuck out of the lesbian who was in the bar bathroom  one holer  directly before me and dropped a gnarly rank dookie like make a raccoon cough type shit\"\"\",  \n",
        "\"\"\"Many of us have witnessed the sad  steady march of Alzheimer s disease as it destroys memory and thinking ability  But what about the physical effects of Alzheimer s which also are significant  but which we tend not to think about as much\"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzp_f1FcHhr8"
      },
      "source": [
        "# **MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KptA2tsxHkcx"
      },
      "source": [
        "## **bert_sequence_classifier_health_mentions**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_sequence_classifier_health_mentions\n",
        "\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "sequenceClassifier = MedicalBertForSequenceClassification.pretrained(\"bert_sequence_classifier_health_mentions\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"document\",\"token\"])\\\n",
        "    .setOutputCol(\"class\")\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    tokenizer,\n",
        "    sequenceClassifier    \n",
        "])\n",
        "\n",
        "df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "result = pipeline.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "eDqj1qGZcfP4",
        "outputId": "48e310df-8e24-4ebc-e7a7-90711a000e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_sequence_classifier_health_mentions download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = result.select(F.explode(F.arrays_zip(\"document.result\", \"class.result\", \"class.metadata\")).alias(\"col\"))\\\n",
        "                .select(F.expr(\"col['0']\").alias(\"Text\"),\n",
        "                        F.expr(\"col['1']\").alias(\"Class\"),\n",
        "                        F.expr(\"col['2']\").alias(\"Confidence\"))"
      ],
      "metadata": {
        "id": "_88HuUezlaGV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"bert_sequence_classifier_health_mentions\"\n",
        "\n",
        "if result.count()>1:    \n",
        "  udf_func = F.udf(lambda x,y:  x[\"Some(\"+str(y)+\")\"])    \n",
        "  print(\"\\n\",model,\"\\n\")    \n",
        "  result.withColumn('Confidence', udf_func(result.Confidence, result.Class)).show(truncate=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVDgLhPsi2Lf",
        "outputId": "d7c8c9e5-4478-4d25-c0ce-c2d2b00d20aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " bert_sequence_classifier_health_mentions \n",
            "\n",
            "+--------------------------------------------------+------------------+----------+\n",
            "|                                              Text|             Class|Confidence|\n",
            "+--------------------------------------------------+------------------+----------+\n",
            "|Got sumatriptan for this week long migraine  I ...|    health_mention|0.99974453|\n",
            "|That Thunder trade alert just now from  almost ...|figurative_mention|   0.99972|\n",
            "|The sickle cell clinic of  still goes on  It is...|     other_mention|  0.999114|\n",
            "|In 2015 I suffered a stroke  This prevented me ...|    health_mention| 0.9994201|\n",
            "|i respect the fuck out of the lesbian who was i...|figurative_mention|0.99958795|\n",
            "|Many of us have witnessed the sad  steady march...|     other_mention| 0.9727036|\n",
            "+--------------------------------------------------+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taaK6AJ6myFW"
      },
      "source": [
        "## **classifierdl_health_mentions**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "bert_embeddings = BertEmbeddings.pretrained(\"bert_embeddings_phs_bert\", \"en\", \"public/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\\\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"sentence\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classifierdl = ClassifierDLModel.pretrained('classifierdl_health_mentions', 'en', 'clinical/models')\\\n",
        "    .setInputCols(['sentence', 'token', 'sentence_embeddings'])\\\n",
        "    .setOutputCol('class')\n",
        "\n",
        "clf_pipeline = Pipeline(stages = [document_assembler,\n",
        "                                  tokenizer,\n",
        "                                  bert_embeddings,\n",
        "                                  embeddingsSentence,\n",
        "                                  classifierdl])\n",
        "\n",
        "df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "result = clf_pipeline.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "SvcvykfhdLG6",
        "outputId": "28ed2f8f-572d-43bd-993d-0b304b56ff0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_embeddings_phs_bert download started this may take some time.\n",
            "Approximate size to download 1.2 GB\n",
            "[OK!]\n",
            "classifierdl_health_mentions download started this may take some time.\n",
            "Approximate size to download 22.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = result.select(F.explode(F.arrays_zip(\"sentence.result\", \"class.result\", \"class.metadata\")).alias(\"col\"))\\\n",
        "                .select(F.expr(\"col['0']\").alias(\"Text\"),\n",
        "                        F.expr(\"col['1']\").alias(\"Class\"),\n",
        "                        F.expr(\"col['2']\").alias(\"Confidence\"))"
      ],
      "metadata": {
        "id": "9eHJcHzvfyb2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTKg1QkQmVnk",
        "outputId": "ad881ae0-38bb-4c71-ebce-063eeffc3d49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------+\n",
            "|Text                                                                                                                                                                                                                                                                       |Class             |Confidence                                                                                                      |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------+\n",
            "|Got sumatriptan for this week long migraine  I thought these were over as a kid  but I guess not  Thought I could just baby it a couple days with water and pedialyte and excedrin  Nope    Why am I so stubborn about continuing to  DO THINGA when I m obviously not well|health_mention    |{sentence -> 0, figurative_mention -> 4.9161895E-7, health_mention -> 0.999987, other_mention -> 1.2503275E-5}  |\n",
            "|That Thunder trade alert just now from  almost gave me a heart attack  Was bracing myself to see THUNDER SENDS RUSS TO Wow That was the briefest emotional roller coaster ever                                                                                             |figurative_mention|{sentence -> 0, figurative_mention -> 0.9999999, health_mention -> 2.2944858E-8, other_mention -> 1.00033965E-7}|\n",
            "|The sickle cell clinic of  still goes on  It is even more for the next 2 months  Ever heard of childhood stroke  One of the leading causes of childhood stroke is sickle cell  Amidst cancer and other                                                                     |other_mention     |{sentence -> 0, figurative_mention -> 2.9859385E-7, health_mention -> 7.835218E-4, other_mention -> 0.9992162}  |\n",
            "|In 2015 I suffered a stroke  This prevented me from playing Rugby League again  It was difficult physically and mentally to recover from  bit four years later  here I am  about to embark on this   Read my story and please donate if you can                            |health_mention    |{sentence -> 0, figurative_mention -> 3.140372E-7, health_mention -> 0.9999814, other_mention -> 1.8276518E-5}  |\n",
            "|i respect the fuck out of the lesbian who was in the bar bathroom  one holer  directly before me and dropped a gnarly rank dookie like make a raccoon cough type shit                                                                                                      |figurative_mention|{sentence -> 0, figurative_mention -> 0.60502684, health_mention -> 1.2155369E-5, other_mention -> 0.3949609}   |\n",
            "|Many of us have witnessed the sad  steady march of Alzheimer s disease as it destroys memory and thinking ability  But what about the physical effects of Alzheimer s which also are significant  but which we tend not to think about as much                             |other_mention     |{sentence -> 0, figurative_mention -> 5.6274706E-7, health_mention -> 1.0315505E-5, other_mention -> 0.99998915}|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"classifierdl_health_mentions\"\n",
        "\n",
        "if result.count()>1:    \n",
        "  udf_func = F.udf(lambda x,y:  x[y])    \n",
        "  print(\"\\n\",model,\"\\n\")    \n",
        "  result.withColumn('Confidence', udf_func(result.Confidence, result.Class)).show(truncate=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slwO9Rb7l_7K",
        "outputId": "ef00e2c3-6372-4c48-88e3-5ab0ee26feba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " classifierdl_health_mentions \n",
            "\n",
            "+--------------------------------------------------+------------------+----------+\n",
            "|                                              Text|             Class|Confidence|\n",
            "+--------------------------------------------------+------------------+----------+\n",
            "|Got sumatriptan for this week long migraine  I ...|    health_mention|  0.999987|\n",
            "|That Thunder trade alert just now from  almost ...|figurative_mention| 0.9999999|\n",
            "|The sickle cell clinic of  still goes on  It is...|     other_mention| 0.9992162|\n",
            "|In 2015 I suffered a stroke  This prevented me ...|    health_mention| 0.9999814|\n",
            "|i respect the fuck out of the lesbian who was i...|figurative_mention|0.60502684|\n",
            "|Many of us have witnessed the sad  steady march...|     other_mention|0.99998915|\n",
            "+--------------------------------------------------+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
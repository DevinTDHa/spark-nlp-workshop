{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9859b3bc-cec4-4189-88ed-37add5484623",
   "metadata": {},
   "source": [
    "# Legal Long Span Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea",
   "metadata": {
    "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9eafb",
   "metadata": {
    "id": "FwJ-P56kq6FU"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Legal/8.Long_Span_Extraction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818acfe-3b90-4e05-93c9-74e67fc55a13",
   "metadata": {},
   "source": [
    "# Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c04089-289c-4c2f-bd89-15077d9991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "with open('../../spark_nlp_for_healthcare_spark_ocr_4.0.2.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "    \n",
    "import os\n",
    "locals().update(license_keys)\n",
    "os.environ.update(license_keys)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fb8124-7c50-429c-8f99-f94477f709d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparknlp version: 4.1.0\n",
      "sparknlp_jsl version: 4.1.0a6\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "print(\"sparknlp version:\",sparknlp.version())\n",
    "print(\"sparknlp_jsl version:\", sparknlp_jsl.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f972974-c3dd-4cd4-bc07-ae1903a72507",
   "metadata": {},
   "source": [
    "# Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1095368c-4476-47a8-8804-936c485a513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparknlp version: 4.1.0\n",
      "sparknlp_jsl version: 4.1.0a6\n",
      ":: loading settings :: url = jar:file:/home/jovyan/work/shared/venvs/qagenerator/lib/python3.8/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-dfa4631d-ef2d-4cbc-851f-47efe6db3c74;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.0.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2 in central\n",
      ":: resolution report :: resolve 746ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.0.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   0   |   0   |   0   ||   17  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-dfa4631d-ef2d-4cbc-851f-47efe6db3c74\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 17 already retrieved (0kB/16ms)\n",
      "22/09/01 12:51:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "import sparknlp\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"sparknlp version:\",sparknlp.version())\n",
    "print(\"sparknlp_jsl version:\", sparknlp_jsl.version())\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"54G\")\\\n",
    "        .config(\"spark.executor.heartbeatInterval\", \"60s\")\\\n",
    "        .config(\"spark.executor.memory\", \"6G\")\\\n",
    "        .config(\"spark.driver.maxResultSize\", \"8G\")\\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:\"+ PUBLIC_VERSION) \\\n",
    "        .config(\"spark.jars\", \"/home/jovyan/work/shared/juan/_FINLEGAL/_QAGenerator/spark-nlp-jsl-4.1.0a6.jar\")\n",
    "spark = builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c8c857d-27dd-4a45-af2d-1a440c86fcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyter-juan-40johnsnowlabs-2ecom.jupyter-notebooks.notebookhub.svc.cluster.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd10365c5b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb8ae4",
   "metadata": {},
   "source": [
    "# NER, Question Generation and Question Answering for Long-Span extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43420eee-1c29-4148-b1c8-fa7884eff9b3",
   "metadata": {},
   "source": [
    "Legal documents are known to be very long. Although you can divide the docuuments into paragraphs or sections, and those into sentences, the resulted sentences are still long.\n",
    "\n",
    "Let's take a look at this example:\n",
    "\n",
    "`Buyer shall use such materials and supplies only in accordance with the present agreement`\n",
    "\n",
    "Not, let's imagine we want to extract three entities:\n",
    "1) The Subject (`Buyer`)\n",
    "2) The Action (`shall use`)\n",
    "3) The Object (what the Buyer shall use? - `such materials and supplies only in accordance with the present agreement`)\n",
    "\n",
    "Although Subject and Action can be totally manageable by traditional NER, it usually struggles the longer the spans are. Trying to model the extraction of Object with a simple NER may result in word fading, when some of the initial or ending words fade into `O`.\n",
    "\n",
    "We present in this notebook a solution for Long Span Extraction: Using an Automatic Question Generator and a Question Answering model to:\n",
    "1) First, using NER, detect entities as the `Subject` and the `Action`. \n",
    "\n",
    "Example: `Buyer - SUBJECT`, `shall use - OBJECT`\n",
    "\n",
    "2) Automatically generate a question to ask for the `Object`, using `Subject` and `Action`;\n",
    "\n",
    "Example: `What shall the Buyer use?`\n",
    "\n",
    "3) Use the question and the sentence to retrieve `Object`, without the limitations of traditional NER;\n",
    "\n",
    "Example: `What shall the Buyer use? such materials and supplies only in accordance with the present agreement`\n",
    "\n",
    "Last, but not least, it's very important to chose a domain-specific Question Answering model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6cb7d-b34f-4974-b63b-c04640f6a668",
   "metadata": {},
   "source": [
    "# Answering the question - `What?`\n",
    "Let's suppose we have the sentence of the example:\n",
    "\n",
    "`The Buyer shall use such materials and supplies only in accordance with the present agreement`\n",
    "\n",
    "In Spark NLP for Legal, we have a trained NER model which is able to extract Subjects (`Buyer`) and Actions (`shall use`) of agreements / obligations with good accuracy.\n",
    "\n",
    "It's also trained for extracting the `Object` using NER, but it's usage is limited due to the restrictions commented above.\n",
    "\n",
    "Let's get SUBJECT and ACTION and automatically create a question with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b342ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"\"\"The Buyer shall use such materials and supplies only in accordance with the present agreement\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2948d346-d522-43b9-9cd7-99430882621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert_qa_xxlargev1_squad2_512 download started this may take some time.\n",
      "Approximate size to download 736.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "sparktokenizer = Tokenizer()\\\n",
    "  .setInputCols(\"document\")\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "tokenClassifier = LegalBertForTokenClassification.pretrained(\"legner_obligations\", \"en\", \"legal/models\")\\\n",
    "  .setInputCols(\"token\", \"document\")\\\n",
    "  .setOutputCol(\"label\")\\\n",
    "  .setCaseSensitive(True)\n",
    "\n",
    "nerconverter = NerConverter()\\\n",
    "  .setInputCols([\"document\", \"token\", \"label\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# setEntities1 says which entity from NER goes first in the question\n",
    "# setEntities2 says which entity from NER goes second in the question\n",
    "# setQuestionMark to True adds a '?' at the end of the sentence (after entity 2)\n",
    "# To sum up, the pattern is     [QUESTIONPRONOUN] [ENTITY1] [ENTITY2] [QUESTIONMARK]\n",
    "qagenerator = NerQAGenerator()\\\n",
    "  .setInputCols([\"ner_chunk\"])\\\n",
    "  .setOutputCol(\"question\")\\\n",
    "  .setQuestionMark(False)\\\n",
    "  .setQuestionPronoun(\"What\")\\\n",
    "  .setEntities1([\"OBLIGATION_SUBJECT\"])\\\n",
    "  .setEntities2([\"OBLIGATION_ACTION\"])\n",
    "\n",
    "qa = RoBertaForQuestionAnswering.pretrained(\"legqa_roberta\",\"en\", \"legal/models\") \\\n",
    "  .setInputCols([\"question\", \"document\"]) \\\n",
    "  .setOutputCol(\"answer\") \\\n",
    "  .setCaseSensitive(True)\n",
    "  \n",
    "pipeline =  Pipeline(stages=[\n",
    "  documentAssembler,\n",
    "  sparktokenizer,\n",
    "  tokenClassifier,\n",
    "  nerconverter,\n",
    "  qagenerator,\n",
    "    qa\n",
    "    ]\n",
    ")\n",
    "\n",
    "p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))\n",
    "\n",
    "res = p_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "183fb2db-1cee-4f78-a486-dd6c9f6abd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|result                 |\n",
      "+-----------------------+\n",
      "|[What Buyer shall use ]|\n",
      "+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.select('question.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5422560c-718e-4606-9054-678371f539b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+\n",
      "|result                                                                     |\n",
      "+---------------------------------------------------------------------------+\n",
      "|[such materials and supplies only in accordance with the present agreement]|\n",
      "+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.select('answer.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85caa4b",
   "metadata": {},
   "source": [
    "Let's get 4 additional examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49ee5ee7-208c-463e-9e04-0af46b69dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Buyer shall use such materials and supplie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Provider will notify the Buyer about the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon agrees to supply 1-year license without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Supplier should ship the product in less t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  The Buyer shall use such materials and supplie...\n",
       "1  The Provider will notify the Buyer about the r...\n",
       "2  Amazon agrees to supply 1-year license without...\n",
       "3  The Supplier should ship the product in less t..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"\"\"The Buyer shall use such materials and supplies only in accordance with the present agreement\"\"\",\n",
    "    \"\"\"The Provider will notify the Buyer about the release date\"\"\",\n",
    "    \"\"\"Amazon agrees to supply 1-year license without fees\"\"\",\n",
    "    \"\"\"The Supplier should ship the product in less than 1 month\"\"\"\n",
    "]\n",
    "\n",
    "pdf = pd.DataFrame(texts, columns = [\"text\"])\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0a5ed-2e38-417d-ad65-57bf9da463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2e5e5-29a7-48a6-a7cb-1c8d4fb3feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = p_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1351eaac-a74a-47e5-9079-44c26abc480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+---------------------------------------------------------------------------+\n",
      "|result                         |result                                                                     |\n",
      "+-------------------------------+---------------------------------------------------------------------------+\n",
      "|[What Buyer shall use ]        |[such materials and supplies only in accordance with the present agreement]|\n",
      "|[What Provider will notify ]   |[theBuyer about the release date]                                          |\n",
      "|[What Amazon agrees to supply ]|[1-year license without fees]                                              |\n",
      "|[What Supplier should ship ]   |[the product in less than 1 month]                                         |\n",
      "+-------------------------------+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.select('question.result', 'answer.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbabd12e-619b-480c-8821-6f504ab9a34b",
   "metadata": {},
   "source": [
    "# Answering the question - `To whom?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec574a03",
   "metadata": {},
   "source": [
    "Let's try to get now the Indirect Object. That is, the recipient of an action. For example, to whom a supplier should send a shipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8bfbdeb-2c00-4aa6-bcea-7f46c90cd7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert_qa_xxlargev1_squad2_512 download started this may take some time.\n",
      "Approximate size to download 736.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "qagenerator = NerQAGenerator()\\\n",
    "  .setInputCols([\"ner_chunk\"])\\\n",
    "  .setOutputCol(\"question\")\\\n",
    "  .setQuestionMark(False)\\\n",
    "  .setQuestionPronoun(\"To whom\")\\\n",
    "  .setEntities1([\"OBLIGATION_ACTION\"])\\\n",
    "  .setEntities2([\"OBLIGATION_SUBJECT\"])\n",
    "  \n",
    "pipeline =  Pipeline(stages=[\n",
    "  documentAssembler,\n",
    "  sparktokenizer,\n",
    "  tokenClassifier,\n",
    "  nerconverter,\n",
    "  qagenerator,\n",
    "    qa\n",
    "    ]\n",
    ")\n",
    "\n",
    "p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))\n",
    "\n",
    "text = \"\"\"The Provider shall send the shipment to the Buyer\"\"\"\n",
    "res = p_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b730864-df23-47ff-9e4e-e4dcd123fdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+------------------------------+----------+\n",
      "|text                                             |result                        |result    |\n",
      "+-------------------------------------------------+------------------------------+----------+\n",
      "|The Provider shall send the shipment to the Buyer|[To whom shall send Provider ]|[theBuyer]|\n",
      "+-------------------------------------------------+------------------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.select('text', 'question.result', 'answer.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6a289-ef6f-45db-bbe7-caa4f8666bd5",
   "metadata": {},
   "source": [
    "# Other clauses\n",
    "This approach works very well also with other clauses and phrases, as temporal ones. Let's try to ask for the deadline of a contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca38094c-52df-445e-9e18-087c85b0a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "qagenerator = NerQAGenerator()\\\n",
    "  .setInputCols([\"ner_chunk\"])\\\n",
    "  .setOutputCol(\"question\")\\\n",
    "  .setQuestionMark(False)\\\n",
    "  .setQuestionPronoun(\"Before when\")\\\n",
    "  .setEntities1([\"OBLIGATION_ACTION\"])\\\n",
    "  .setEntities2([\"OBLIGATION_SUBJECT\"])\n",
    "  \n",
    "pipeline =  Pipeline(stages=[\n",
    "  documentAssembler,\n",
    "  sparktokenizer,\n",
    "  tokenClassifier,\n",
    "  nerconverter,\n",
    "  qagenerator,\n",
    "    qa\n",
    "    ]\n",
    ")\n",
    "\n",
    "p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))\n",
    "\n",
    "text = \"\"\"The customer should sign the contract before May, 2023\"\"\"\n",
    "res = p_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46c831a5-43f6-4511-86fa-76a076fee510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+-----------------------------------+-----------------+\n",
      "|text                                                  |result                             |result           |\n",
      "+------------------------------------------------------+-----------------------------------+-----------------+\n",
      "|The customer should sign the contract before May, 2023|[Before when should sign customer ]|[beforeMay, 2023]|\n",
      "+------------------------------------------------------+-----------------------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.select('text', 'question.result', 'answer.result').show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca1c4b8877e01dec1d65bc94ac0771fb7b4e7d433b24c0ced0afdc05f796f65d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
